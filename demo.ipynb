{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb07323-aea6-4eb9-b45a-1f2c5761f9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import QIGen\n",
    "import torch\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a856859-71f1-4fb3-a95e-f4511b7a3051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/tommaso/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [00:36<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "\n",
    "path = \"../models/path\" # PATH TO YOUR MODELS \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83d1203-131f-41bc-af81-7772847e091c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"../checkpoint/path.pt\",map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032e5a4f-6599-45dc-9105-c7f8925239ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l1 = 2**18 # Level 1 cache in bits\n",
    "p = 64 # number of cores\n",
    "bits = 3 # bits used for the model\n",
    "gs = 128 # Group size (-1 means full column)\n",
    "arch = 'llama' #or opt\n",
    "\n",
    "qzeros = not (bits == 3)\n",
    "qmodel = QIGen.swap_modules(arch, model, checkpoint, bits=bits, p=p, gs=gs,\n",
    "                                     l1=l1, inplace=True, hint=1,\n",
    "                                     verbose=False, qzeros=qzeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab68b96-26c2-4346-9926-66f4a7ac3984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"My favorite vacation was \"\n",
    "result_length = 128\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "generation_config = transformers.GenerationConfig(\n",
    "    temperature=0.8, #0.8\n",
    "    top_p=0.95, #0.95\n",
    "    top_k=40, #40\n",
    "    num_beams=1,\n",
    "    min_new_tokens=result_length,\n",
    "    max_new_tokens=result_length,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.1, #1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e935c6dd-f2b1-405c-959d-b7f0b2785f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.422704935073853  ⁇  My favorite vacation was 10 years ago. I went to the beach with my family and friends. We stayed in a hotel for two days. It was very hot, but we had fun. We swam in the ocean and played volleyball on the beach. We also went shopping at the mall. We bought some souvenirs and gifts for our families. We were so tired after the trip, but it was worth it.\n",
      "My favorite vacation was 10 years ago. I went to the beach with my family and friends. We stayed in a hotel for two days. It was very hot, but we had fun\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "start = time.time()\n",
    "output = tokenizer.decode(qmodel.generate(inputs[\"input_ids\"],generation_config=generation_config)[0])\n",
    "end = time.time() - start\n",
    "print(end, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
